# FinSight Copilot ğŸ¤–ğŸ“Š

An intelligent financial analysis assistant that leverages RAG (Retrieval-Augmented Generation) to provide insights from financial reports, market data, and competitor analysis.

## ğŸ¯ Project Overview

FinSight Copilot is designed to help financial professionals and analysts by:
- Analyzing 10-K/10-Q filings and financial reports
- Providing competitive intelligence and market insights
- Generating actionable recommendations for product improvements
- Offering real-time financial data analysis

## ğŸ“ Project Structure

```
finsight-copilot/
â”‚
â”œâ”€â”€ data/                    # Raw financial reports, transcripts, scraped data
â”œâ”€â”€ processed_data/          # Cleaned & chunked data
â”œâ”€â”€ embeddings/              # FAISS or Chroma index
â”œâ”€â”€ models/                  # Quantized LLMs or LoRA adapters
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # Backend + RAG pipeline âœ…
â”‚   â”œâ”€â”€ prompts.py           # Prompt templates âœ…
â”‚   â””â”€â”€ rag_utils.py         # Embedding, retrieval logic âœ…
â”œâ”€â”€ notebooks/               # Exploration, experiments, training
â”‚   â”œâ”€â”€ fetch_stock_data.py  # Stock data collection âœ…
â”‚   â”œâ”€â”€ fetch_10k.py         # SEC filing downloader âœ…
â”‚   â””â”€â”€ data_exploration.py  # Data analysis script âœ…
â”œâ”€â”€ ui/                      # Streamlit or CLI-based chat interface
â”‚   â””â”€â”€ app.py               # Streamlit UI âœ…
â”œâ”€â”€ requirements.txt         # Dependencies âœ…
â”œâ”€â”€ setup.py                 # Installation script âœ…
â”œâ”€â”€ env.example              # Environment template âœ…
â””â”€â”€ README.md                # Project overview âœ…
```

## ğŸš¦ Development Phases

### Phase 1: Project Setup + Data Collection (2-3 days) âœ… **COMPLETED**
- [x] Create project folder structure âœ…
- [x] Install dependencies âœ…
- [x] Create data collection scripts âœ…
- [x] Build Streamlit UI âœ…
- [x] Set up RAG pipeline foundation âœ…
- [x] Create comprehensive prompt templates âœ…

**ğŸ‰ Phase 1 Status: COMPLETE!** 

### Phase 2: Data Cleaning + Preprocessing (3-5 days) ğŸ”„ **NEXT**
- [ ] Clean raw text data
- [ ] Chunk text into 512-1024 token segments
- [ ] Add metadata (source, date, type)
- [ ] Save processed data

### Phase 3: Embedding + Vector DB Setup (2-4 days)
- [ ] Generate embeddings using MiniLM or FinBERT
- [ ] Create FAISS/Chroma vector store
- [ ] Build retrieval function

### Phase 4: LLM Integration + RAG Pipeline (4-6 days)
- [ ] Set up prompt templates
- [ ] Load local quantized model
- [ ] Connect retriever + generator
- [ ] Create backend API

### Phase 5: Interface + Demo App (3-5 days)
- [ ] Build Streamlit UI
- [ ] Connect to RAG backend
- [ ] Add example prompts
- [ ] Upload functionality

### Phase 6: Fine-tuning (Optional - 5-7 days)
- [ ] Prepare training data
- [ ] Implement LoRA fine-tuning
- [ ] Train on phi-2 or tinyllama

## ğŸš€ Quick Start

### Option 1: Automated Setup (Recommended)
```bash
# Clone the repository
git clone <repository-url>
cd finsight-copilot

# Run automated setup
python setup.py
```

### Option 2: Manual Setup
```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Create environment file
cp env.example .env
# Edit .env with your API keys (optional)

# 3. Collect initial data
cd notebooks
python fetch_stock_data.py
python fetch_10k.py

# 4. Run the application
streamlit run ui/app.py
```

## ğŸ“Š Data Collection

The project includes automated data collection scripts:

### Stock Data Collection
```bash
cd notebooks
python fetch_stock_data.py
```
**Collects:**
- Historical stock prices (1 year)
- Company information and metrics
- Financial statements (income, balance sheet, cash flow)
- Market data for 25+ major companies

### SEC Filing Download
```bash
cd notebooks
python fetch_10k.py
```
**Downloads:**
- 10-K annual reports
- 10-Q quarterly reports
- Cleaned text versions
- Filing metadata

### Data Exploration
```bash
cd notebooks
python data_exploration.py
```
**Analyzes:**
- Performance metrics
- Data quality assessment
- Sector analysis
- Filing statistics

## ğŸ› ï¸ Key Features

- **Intelligent Document Analysis**: Process and understand complex financial documents
- **Competitive Intelligence**: Analyze competitor positioning and market trends
- **Real-time Insights**: Get up-to-date financial data and analysis
- **Customizable Prompts**: Tailored prompts for different analysis types
- **Local Processing**: Run entirely on your machine for data privacy

## ğŸ“Š Data Sources

- **SEC EDGAR**: 10-K, 10-Q filings
- **Yahoo Finance**: Market data, financial summaries
- **Company Websites**: Product information, pricing
- **Financial News**: Market analysis and trends

## ğŸ”§ Technical Stack

- **Backend**: Python, LangChain, Transformers
- **Vector Database**: FAISS/Chroma
- **Embeddings**: Sentence-Transformers, FinBERT
- **UI**: Streamlit, Gradio
- **Models**: Local quantized LLMs (llama.cpp, Hugging Face)

## ğŸ” FAISS Index Management

All backend code uses a centralized utility function `get_faiss_index_dir()` (in `backend/finsight_app/path_utils.py`) to resolve the FAISS vector index directory:

- **Directory:** `embeddings/finsight_index/`
- **Index file:** `embeddings/finsight_index/index.faiss`
- **Chunk mapping:** `embeddings/finsight_index/chunk_mapping.pkl`

This ensures:
- No hardcoded or conflicting paths
- The app works from both the project root and backend/ directories
- Easy debugging and onboarding for new contributors

**Example usage:**
```python
from finsight_app.path_utils import get_faiss_index_dir
faiss_index_path = get_faiss_index_dir()
index_file_path = os.path.join(faiss_index_path, "index.faiss")
```

> Always use this utility for any code that reads or writes the FAISS index or chunk mapping files.

## ğŸ¯ Current Capabilities

### âœ… What's Working Now
1. **Data Collection**: Automated stock data and SEC filing downloads
2. **Data Processing**: Text cleaning, chunking, and metadata extraction
3. **UI Framework**: Complete Streamlit interface with navigation
4. **RAG Foundation**: Embedding generation and retrieval system
5. **Prompt System**: Comprehensive templates for different analysis types

### ğŸ”„ What's Next (Phase 2)
1. **Data Preprocessing**: Clean and chunk all collected documents
2. **Vector Database**: Create FAISS index for semantic search
3. **Model Integration**: Connect local LLM for generation
4. **End-to-End Testing**: Complete RAG pipeline validation

## ğŸ“ˆ Usage Examples

### CLI Interface
```bash
# General analysis
python app/main.py --query "Analyze Apple's competitive position" --type competitive

# Company-specific analysis
python app/main.py --company AAPL --type risk

# Process data
python app/main.py --process-data
```

### Web Interface
```bash
streamlit run ui/app.py
```
Then navigate to:
- **Overview**: Project status and features
- **Data Overview**: Dataset statistics and quality
- **Analysis**: Custom financial analysis queries
- **Quick Analysis**: Predefined analysis types
- **Data Collection**: Upload and manage data

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For questions or issues, please open an issue on GitHub or contact the development team.

---

**Built with â¤ï¸ for financial professionals**

### ğŸ‰ Phase 1 Complete!
**Status**: âœ… All Phase 1 objectives achieved
**Next**: Ready to begin Phase 2 (Data Preprocessing)
**Timeline**: 2-3 days for Phase 2 completion 